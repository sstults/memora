# -------------------------
# Core
# -------------------------
NODE_ENV=development
PORT=4000

# -------------------------
# OpenSearch
# -------------------------
OPENSEARCH_URL=http://localhost:19200
# OPENSEARCH_USERNAME=admin
# OPENSEARCH_PASSWORD=admin
# For self-signed local dev certs set to false
OPENSEARCH_SSL_REJECT_UNAUTHORIZED=true

# Index naming overrides (optional)
MEMORA_METRICS_INDEX=mem-metrics
MEMORA_SEMANTIC_INDEX=mem-semantic
MEMORA_FACTS_INDEX=mem-facts
MEMORA_EPI_PREFIX=mem-episodic-
MEMORA_IDEMP_INDEX=mem-idempotency

# -------------------------
# Embeddings
# -------------------------
# If set, Memora will POST to this endpoint with {texts, dim}
# and expect {vectors: number[][]}
# If unset, a deterministic hash-based fallback is used
# EMBEDDING_ENDPOINT=http://localhost:8080/embed  # optional; if unset, deterministic local fallback is used
# EMBEDDING_API_KEY=changeme
MEMORA_EMBED_DIM=1024
MEMORA_EMBED_TIMEOUT_MS=8000
MEMORA_EMBED_RETRIES=3

# -------------------------
# OpenSearch ML Pipelines (optional)
# -------------------------
# When using OpenSearch ML Commons to generate embeddings via pipelines:
# - Set MEMORA_EMBED_PROVIDER=opensearch_pipeline
# - Ensure an ONNX model is registered/deployed (e.g., MiniLM-L6 384-dim)
# - Create an ingest pipeline with text_embedding processor referencing your model_id
# - Optionally attach the ingest pipeline as the index default_pipeline
#
# Provider selection
# MEMORA_EMBED_PROVIDER=opensearch_pipeline
#
# Model configuration (defaults for local/dev)
# OPENSEARCH_ML_MODEL_NAME=huggingface/sentence-transformers/all-MiniLM-L6-v2
# OPENSEARCH_ML_MODEL_VERSION=1.0.2
# OPENSEARCH_ML_MODEL_FORMAT=ONNX
#
# Pipelines
# MEMORA_OS_INGEST_PIPELINE_NAME=mem-text-embed
# MEMORA_OS_DEFAULT_PIPELINE_ATTACH=false
#
# Vector dim alignment
# MEMORA_OS_AUTOFIX_VECTOR_DIM=false
# Note: MiniLM-L6 ONNX outputs 384-dim vectors. If using that model, set:
# MEMORA_EMBED_DIM=384
# and ensure index mappings match (or enable MEMORA_OS_AUTOFIX_VECTOR_DIM=true).

# -------------------------
# Reranker (optional)
# -------------------------
# If set, Memora will POST to this endpoint with {query, candidates}
# and expect {scores: number[]}
RERANK_ENDPOINT=http://localhost:8081/rerank
RERANK_API_KEY=changeme
RERANK_TIMEOUT_MS=1500
RERANK_MAX_RETRIES=2

# -------------------------
# Evaluation (optional)
# -------------------------
# Mirror eval.log entries into the episodic log
MEMORA_EVAL_EPISODIC_MIRROR=false

# -------------------------
# Memory defaults
# -------------------------
MEMORA_DEFAULT_BUDGET=12
MEMORA_RERANK_ENABLED=false
# Max number of semantic chunks to upsert per memory.write (backpressure cap; default 64)
MEMORA_WRITE_MAX_CHUNKS=64

# -------------------------
# Logging / Debug
# -------------------------
DEBUG=memora:*
LOG_LEVEL=info
